{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80ded5f",
   "metadata": {},
   "source": [
    "# Task -> Evaluating the models on out sample data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9ec0c5",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9964c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pragyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "import gc\n",
    "import re\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d1eb7",
   "metadata": {},
   "source": [
    "# Get the models from their paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f5d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the fine tuned models \n",
    "base_model = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "fine_tuned_model_oneInstruction = \"llama2-finetunedSentimentClassificationOneInstruction\"\n",
    "fine_tuned_model_twoInstruction = \"llama2-finetunedSentimentClassificationTwoInstruction\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ff186",
   "metadata": {},
   "source": [
    "# Generating some manual out of sample data for testing the base and fine tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be103e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    \"### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response:\",\n",
    "    \n",
    "    \"### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response:\",\n",
    "    \n",
    "    \"Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response:\",\n",
    "    \n",
    "    \"### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response:\",\n",
    "    \n",
    "    \"### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response:\",\n",
    "    \n",
    "    \"### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response:\",\n",
    "    \n",
    "    \" Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response:\",\n",
    "    \n",
    "    \"### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response:\",\n",
    "    \n",
    "    \"### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response:\",\n",
    "    \n",
    "    \"### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response:\"\n",
    "]\n",
    "\n",
    "\n",
    "responsesManual = [\n",
    "    \"Artificial Intelligence transforming industries becoming a pivotal technology\", \n",
    "    \n",
    "    \"¡Buen día! ¿Cómo estás?\",\n",
    "    \n",
    "    \"positive\", \n",
    "    \n",
    "    \"1889\", \n",
    "    \n",
    "    \"Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\",\n",
    "    \n",
    "    \"tone is exciting\", \n",
    "    \n",
    "    \"ruled the world\", \n",
    "    \n",
    "    \"She felt tired and left the party early\",\n",
    "    \n",
    "    \"In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\",\n",
    "    \n",
    "    \"Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2928b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary with prompt and response\n",
    "\n",
    "out_of_sample_data = []\n",
    "\n",
    "for i in range(len(instructions)):\n",
    "    out_of_sample_data.append({\"CompleteText\": instructions[i] + \" \" + responsesManual[i],\"Prompt\": instructions[i], \"Response\": responsesManual[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe6619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'CompleteText': \"### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response: Artificial Intelligence transforming industries becoming a pivotal technology\", 'Prompt': \"### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response:\", 'Response': 'Artificial Intelligence transforming industries becoming a pivotal technology'}, {'CompleteText': '### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response: ¡Buen día! ¿Cómo estás?', 'Prompt': '### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response:', 'Response': '¡Buen día! ¿Cómo estás?'}, {'CompleteText': 'Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response: positive', 'Prompt': 'Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response:', 'Response': 'positive'}, {'CompleteText': '### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response: 1889', 'Prompt': '### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response:', 'Response': '1889'}, {'CompleteText': \"### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response: Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\", 'Prompt': '### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response:', 'Response': \"Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\"}, {'CompleteText': \"### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response: tone is exciting\", 'Prompt': \"### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response:\", 'Response': 'tone is exciting'}, {'CompleteText': ' Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response: ruled the world', 'Prompt': ' Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response:', 'Response': 'ruled the world'}, {'CompleteText': '### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response: She felt tired and left the party early', 'Prompt': '### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response:', 'Response': 'She felt tired and left the party early'}, {'CompleteText': \"### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response: In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\", 'Prompt': '### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response:', 'Response': \"In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\"}, {'CompleteText': '### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response: Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.', 'Prompt': '### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response:', 'Response': 'Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.'}]\n"
     ]
    }
   ],
   "source": [
    "print(out_of_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb3e302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all the instruct here \n",
    "training_original = []\n",
    "training_instances = []\n",
    "training_instance_forPredictionList = []\n",
    "\n",
    "# loop to create the instruction training data for fine tuning \n",
    "for j in out_of_sample_data:\n",
    "    training_instance_forPredictionList.append(j['Prompt'])\n",
    "    training_instances.append(j['Response'])\n",
    "    training_original.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "969f290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CompleteText': \"### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response: Artificial Intelligence transforming industries becoming a pivotal technology\", 'Prompt': \"### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response:\", 'Response': 'Artificial Intelligence transforming industries becoming a pivotal technology'}\n",
      "\n",
      "### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response:\n",
      "---\n",
      "Artificial Intelligence transforming industries becoming a pivotal technology\n"
     ]
    }
   ],
   "source": [
    "print(training_original[0])\n",
    "print()\n",
    "print(training_instance_forPredictionList[0])\n",
    "print(\"---\")\n",
    "print(training_instances[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d4fc3",
   "metadata": {},
   "source": [
    "# Generating the responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6917f0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf6f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_sentiment(text):\n",
    "    match = re.search(r\"### Response:\\s*(.*(?:\\n.*)*)\", text)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f34ca1",
   "metadata": {},
   "source": [
    "## Using the Base Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "692f7fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24471024e45748e3aaeea64cc2880e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pragyan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/pragyan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/pragyan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/pragyan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  {'CompleteText': \"### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response: Artificial Intelligence transforming industries becoming a pivotal technology\", 'Prompt': \"### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response:\", 'Response': 'Artificial Intelligence transforming industries becoming a pivotal technology'}\n",
      "Prompt:  ### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response:\n",
      "Reference:  Artificial Intelligence transforming industries becoming a pivotal technology\n",
      "Candidate:  ### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response: * Artificial Intelligence (AI) is transforming various industries, improving efficiency, and enabling new possibilities. * AI is becoming a pivotal technology in the modern world. * Examples of industries transformed by AI include healthcare, finance, and transportation. * AI is improving decision-making processes and enabling businesses to make data-driven decisions. * AI is also creating new job opportunities and transforming the way we work. * The potential of AI is vast, and it will continue to shape the future of various industries and society as\n",
      "Candidate Pulled:  * Artificial Intelligence (AI) is transforming various industries, improving efficiency, and enabling new possibilities. * AI is becoming a pivotal technology in the modern world. * Examples of industries transformed by AI include healthcare, finance, and transportation. * AI is improving decision-making processes and enabling businesses to make data-driven decisions. * AI is also creating new job opportunities and transforming the way we work. * The potential of AI is vast, and it will continue to shape the future of various industries and society as\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0223e6770c245c9905a44357964ccea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ff0e9a0d814b5bb38f2ea3c8e45751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.08 seconds, 12.28 sentences/sec\n",
      "Original:  {'CompleteText': '### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response: ¡Buen día! ¿Cómo estás?', 'Prompt': '### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response:', 'Response': '¡Buen día! ¿Cómo estás?'}\n",
      "Prompt:  ### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response:\n",
      "Reference:  ¡Buen día! ¿Cómo estás?\n",
      "Candidate:  ### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response: ¡Buenos días! ¿Cómo estás? (Good morning! How are you?)\n",
      "Candidate Pulled:  ¡Buenos días! ¿Cómo estás? (Good morning! How are you?)\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccc83a9bd904aa2bccb127ebdc8fb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f10d21313544718a4c657f365e440b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.04 seconds, 23.69 sentences/sec\n",
      "Original:  {'CompleteText': 'Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response: positive', 'Prompt': 'Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response:', 'Response': 'positive'}\n",
      "Prompt:  Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response:\n",
      "Reference:  positive\n",
      "Candidate:  Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response: Positive\n",
      "Candidate Pulled:  Positive\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d146473543249a0bf4a7bc2b99b6372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604396e97a8c411fac6bc0ae0532c08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.47 sentences/sec\n",
      "Original:  {'CompleteText': '### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response: 1889', 'Prompt': '### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response:', 'Response': '1889'}\n",
      "Prompt:  ### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response:\n",
      "Reference:  1889\n",
      "Candidate:  ### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response: Based on the given passage, the Eiffel Tower was constructed in 1889.\n",
      "Candidate Pulled:  Based on the given passage, the Eiffel Tower was constructed in 1889.\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73fef3c45eb4d94af64bfdba921429c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f6a732b8834586b0c7473ea2f69538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.83 sentences/sec\n",
      "Original:  {'CompleteText': \"### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response: Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\", 'Prompt': '### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response:', 'Response': \"Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\"}\n",
      "Prompt:  ### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response:\n",
      "Reference:  Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\n",
      "Candidate:  ### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response: Bob: I've been good, just busy with work and stuff. 😊 How about you? Alice: I've been good too. Just got back from a trip to Hawaii. 🏖️ It was amazing! Bob: Oh wow, that sounds great! I've always wanted to go to Hawaii. How was it? Alice: It was amazing! The beaches were beautiful and the weather was perfect. I even learned how to surf. Bob: That's awesome! I've always wanted to learn how to surf. Maybe one day I\n",
      "Candidate Pulled:  Bob: I've been good, just busy with work and stuff. 😊 How about you? Alice: I've been good too. Just got back from a trip to Hawaii. 🏖️ It was amazing! Bob: Oh wow, that sounds great! I've always wanted to go to Hawaii. How was it? Alice: It was amazing! The beaches were beautiful and the weather was perfect. I even learned how to surf. Bob: That's awesome! I've always wanted to learn how to surf. Maybe one day I\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d3ed4b2e0545e4b325ca28f3a6563d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38db592a356a4a1f9f64ee296221c41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 30.78 sentences/sec\n",
      "Original:  {'CompleteText': \"### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response: tone is exciting\", 'Prompt': \"### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response:\", 'Response': 'tone is exciting'}\n",
      "Prompt:  ### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response:\n",
      "Reference:  tone is exciting\n",
      "Candidate:  ### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response: The tone of the text is positive and optimistic. The use of words such as \"really excited\" and \"believe\" convey a sense of enthusiasm and confidence. The tone is also energetic and motivational, suggesting that the speaker is eager to tackle the challenges ahead. Overall, the tone is upbeat and encouraging.\n",
      "Candidate Pulled:  The tone of the text is positive and optimistic. The use of words such as \"really excited\" and \"believe\" convey a sense of enthusiasm and confidence. The tone is also energetic and motivational, suggesting that the speaker is eager to tackle the challenges ahead. Overall, the tone is upbeat and encouraging.\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099081c1a84a469b8f25281e85ef0883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52307ae985774dbc8bbce1105168cb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.01 sentences/sec\n",
      "Original:  {'CompleteText': ' Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response: ruled the world', 'Prompt': ' Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response:', 'Response': 'ruled the world'}\n",
      "Prompt:   Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response:\n",
      "Reference:  ruled the world\n",
      "Candidate:   Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response: lived in a magnificent castle with his parents, the king and queen.\n",
      "\n",
      "Please provide the correct answer for the blank space.\n",
      "Candidate Pulled:  lived in a magnificent castle with his parents, the king and queen.\n",
      "\n",
      "Please provide the correct answer for the blank space.\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9cfdf635d74e2d8f03a26cd4d5cf33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa581d594018434cafe05dca9428bd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.69 sentences/sec\n",
      "Original:  {'CompleteText': '### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response: She felt tired and left the party early', 'Prompt': '### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response:', 'Response': 'She felt tired and left the party early'}\n",
      "Prompt:  ### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response:\n",
      "Reference:  She felt tired and left the party early\n",
      "Candidate:  ### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response: She chose to depart from the gathering before its conclusion because she experienced fatigue.\n",
      "Candidate Pulled:  She chose to depart from the gathering before its conclusion because she experienced fatigue.\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80a5e7fc1144a2586c1f14b557e229b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5c5331d3a644f48ea719316424d0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.64 sentences/sec\n",
      "Original:  {'CompleteText': \"### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response: In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\", 'Prompt': '### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response:', 'Response': \"In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\"}\n",
      "Prompt:  ### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response:\n",
      "Reference:  In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\n",
      "Candidate:  ### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response: Once upon a time, in a far-off kingdom, a brave knight named King embarked on a perilous quest to save his kingdom from the clutches of a dark sorcerer. The sorcerer, who had been terrorizing the kingdom for months, had finally revealed his true intentions: to take over the kingdom and rule with an iron fist. King, determined to stop the sorcerer, set out on his trusty steed, armed with his sword and shield. He rode through treacherous mountains and dark forests, facing countless dangers along the way. He batt\n",
      "Candidate Pulled:  Once upon a time, in a far-off kingdom, a brave knight named King embarked on a perilous quest to save his kingdom from the clutches of a dark sorcerer. The sorcerer, who had been terrorizing the kingdom for months, had finally revealed his true intentions: to take over the kingdom and rule with an iron fist. King, determined to stop the sorcerer, set out on his trusty steed, armed with his sword and shield. He rode through treacherous mountains and dark forests, facing countless dangers along the way. He batt\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af7429b792b4437ad227b7a10ff0b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9be4c456d9141b48082f4b960ee1c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 29.71 sentences/sec\n",
      "Original:  {'CompleteText': '### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response: Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.', 'Prompt': '### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response:', 'Response': 'Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.'}\n",
      "Prompt:  ### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response:\n",
      "Reference:  Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.\n",
      "Candidate:  ### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response: Sure, here are five similar examples: 1. Sarah enjoys swimming in the ocean every summer. 2. Michael likes playing basketball with his friends every evening. 3. Emily loves reading books in her free time. 4. David enjoys traveling to new countries every year. 5. Rachel likes practicing yoga every morning.\n",
      "Candidate Pulled:  Sure, here are five similar examples: 1. Sarah enjoys swimming in the ocean every summer. 2. Michael likes playing basketball with his friends every evening. 3. Emily loves reading books in her free time. 4. David enjoys traveling to new countries every year. 5. Rachel likes practicing yoga every morning.\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336c2fb4c1194c92b305ad9b8286a69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034caab8bf7642bba60845c9ce0e089b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 30.62 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer_base = AutoTokenizer.from_pretrained(base_model)\n",
    "# model_oneInstruction = AutoModelForCausalLM.from_pretrained(fine_tuned_model_oneInstruction).to(device)\n",
    "model_base = AutoModelForCausalLM.from_pretrained(base_model, device_map=\"auto\")\n",
    "\n",
    "totalBlueScore_base = []\n",
    "totalROUEScore_base = []\n",
    "totalBERTScore_base = []\n",
    "\n",
    "\n",
    "for i in range(len(training_instance_forPredictionList)):\n",
    "    pipe1 = pipeline(task=\"text-generation\", model=model_base, tokenizer=tokenizer_base)\n",
    "    result1 = pipe1(training_instance_forPredictionList[i], max_new_tokens=128)\n",
    "    \n",
    "    # reference -> ground truth \n",
    "    # candidate -> prediction \n",
    "    reference = str(training_original[i]['Response'])\n",
    "    candidate_notPulled = result1[0]['generated_text']\n",
    "    candiate_sentimentPulled = str(extract_candidate_sentiment(candidate_notPulled))\n",
    "    print(\"Original: \", training_original[i])\n",
    "    print(\"Prompt: \", training_instance_forPredictionList[i])\n",
    "    print(\"Reference: \", reference)\n",
    "    print(\"Candidate: \", candidate_notPulled)\n",
    "    print(\"Candidate Pulled: \", candiate_sentimentPulled)\n",
    "    print(\"**********\")\n",
    "    \n",
    "    # reference_tokens = word_tokenize(reference)\n",
    "    # candidate_tokens = word_tokenize(candiate_sentimentPulled)\n",
    "    \n",
    "    # print(\"Score: \")\n",
    "    # Calculating BLEU score\n",
    "    bleu_score = sentence_bleu([reference], candiate_sentimentPulled)\n",
    "    # print(f\"BLEU score: {bleu_score}\")\n",
    "    totalBlueScore_base.append(bleu_score)\n",
    "    \n",
    "    # Creating a ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "    # Calculating ROUGE-L\n",
    "    scores = scorer.score(reference, candiate_sentimentPulled)\n",
    "    # print(f\"ROUGE-L score: {scores['rougeL'].fmeasure}\")\n",
    "    totalROUEScore_base.append(scores['rougeL'].fmeasure)\n",
    "    \n",
    "    # Calculating BERTScore\n",
    "    P, R, F1 = score([candiate_sentimentPulled], [reference], lang=\"en\", verbose=True)\n",
    "\n",
    "    # Printing the F1 score\n",
    "    # print(f\"BERTScore F1: {F1.mean().item()}\")\n",
    "    totalBERTScore_base.append(F1.mean().item())\n",
    "    \n",
    "    # print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2efa9bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11292"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tokenizer_base\n",
    "del model_base\n",
    "del pipe1\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d924e",
   "metadata": {},
   "source": [
    "## Using fine tuned Model with only one instruction -> custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c91d25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bedca1890824246a28b153000f82f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pragyan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/pragyan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  {'CompleteText': \"### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response: Artificial Intelligence transforming industries becoming a pivotal technology\", 'Prompt': \"### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response:\", 'Response': 'Artificial Intelligence transforming industries becoming a pivotal technology'}\n",
      "Prompt:  ### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response:\n",
      "Reference:  Artificial Intelligence transforming industries becoming a pivotal technology\n",
      "Candidate:  ### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world.\n",
      "Candidate Pulled:  Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world.\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02238fd4574b4cb3923bc12587ff2037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac1fff82573460181d68f32a1005bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.27 sentences/sec\n",
      "Original:  {'CompleteText': '### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response: ¡Buen día! ¿Cómo estás?', 'Prompt': '### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response:', 'Response': '¡Buen día! ¿Cómo estás?'}\n",
      "Prompt:  ### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response:\n",
      "Reference:  ¡Buen día! ¿Cómo estás?\n",
      "Candidate:  ### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response: Good morning! I'm doing well, thanks for asking.  I'm just getting ready to go to work. ### Sentiment: Neutral ### Confidence: High ### Topic: Work ### Emotion: Neutral ### Strength: 7 ### Weakness: 3 ### Word: Good ### Sentiment: Neutral ### Confidence: High ### Topic: Work ### Emotion: Neutral ### Strength: 7 ### Weakness: 3 ### Word: Good ### Sentiment: Neutral ### Confidence: High ### Topic: Work ### Emotion:\n",
      "Candidate Pulled:  Good morning! I'm doing well, thanks for asking.  I'm just getting ready to go to work. ### Sentiment: Neutral ### Confidence: High ### Topic: Work ### Emotion: Neutral ### Strength: 7 ### Weakness: 3 ### Word: Good ### Sentiment: Neutral ### Confidence: High ### Topic: Work ### Emotion: Neutral ### Strength: 7 ### Weakness: 3 ### Word: Good ### Sentiment: Neutral ### Confidence: High ### Topic: Work ### Emotion:\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pragyan/.local/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/pragyan/.local/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876829551b2f4e8eba5bf670e668eb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72cb522d1734e28b534e4d85304bd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.74 sentences/sec\n",
      "Original:  {'CompleteText': 'Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response: positive', 'Prompt': 'Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response:', 'Response': 'positive'}\n",
      "Prompt:  Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response:\n",
      "Reference:  positive\n",
      "Candidate:  Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response: @michelle_mcdonald I'm glad you enjoyed it! ### Sentiment: Positive ### Hashtags: #movies #fantasticbeasts ### Sentiment: Positive ### Hashtags: #movies #fantasticbeasts ### Sentiment: Positive ### Hashtags: #movies #fantasticbeasts ### Sentiment: Positive ### Hashtags: #movies #fantasticbeasts ### Sentiment: Positive ### Hashtags: #movies #fantasticbeasts ### Sentiment: Positive ### Hashtags:\n",
      "Candidate Pulled:  @michelle_mcdonald I'm glad you enjoyed it! ### Sentiment: Positive ### Hashtags: #movies #fantasticbeasts ### Sentiment: Positive ### Hashtags: #movies #fantasticbeasts ### Sentiment: Positive ### Hashtags: #movies #fantasticbeasts ### Sentiment: Positive ### Hashtags: #movies #fantasticbeasts ### Sentiment: Positive ### Hashtags: #movies #fantasticbeasts ### Sentiment: Positive ### Hashtags:\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf60c58fe0245b5912ff5a231bd0359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7de56b0e8b94510b38dd16e8dca7180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.82 sentences/sec\n",
      "Original:  {'CompleteText': '### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response: 1889', 'Prompt': '### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response:', 'Response': '1889'}\n",
      "Prompt:  ### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response:\n",
      "Reference:  1889\n",
      "Candidate:  ### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response: 1889 ### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response: 1889 ### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response: 188\n",
      "Candidate Pulled:  1889 ### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response: 1889 ### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response: 188\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f763c2153c4778917b54a5ad1d04d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ccd8c7ee984f718f43ec991e027791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.87 sentences/sec\n",
      "Original:  {'CompleteText': \"### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response: Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\", 'Prompt': '### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response:', 'Response': \"Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\"}\n",
      "Prompt:  ### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response:\n",
      "Reference:  Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\n",
      "Candidate:  ### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response: Bob: I've been good, just busy with work.  I'm going to be out of town for a few days, but I'll be back soon. ### Input: Alice: Oh, okay. I'll miss you. ### Response: Bob: Yeah, I'll miss you too. ### Input: Alice: I'll be here when you get back. ### Response: Bob: I'll be back soon. ### Input: Alice: I'm going to miss you. ### Response: Bob: I'll miss you too. ### Input: Alice: I'll be here when\n",
      "Candidate Pulled:  Bob: I've been good, just busy with work.  I'm going to be out of town for a few days, but I'll be back soon. ### Input: Alice: Oh, okay. I'll miss you. ### Response: Bob: Yeah, I'll miss you too. ### Input: Alice: I'll be here when you get back. ### Response: Bob: I'll be back soon. ### Input: Alice: I'm going to miss you. ### Response: Bob: I'll miss you too. ### Input: Alice: I'll be here when\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf62877377444df9f669353fe65575b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a43248888c4073890c3c18a61ae92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.47 sentences/sec\n",
      "Original:  {'CompleteText': \"### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response: tone is exciting\", 'Prompt': \"### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response:\", 'Response': 'tone is exciting'}\n",
      "Prompt:  ### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response:\n",
      "Reference:  tone is exciting\n",
      "Candidate:  ### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response: I'm glad you're excited about the new project! I'm sure it will be a great success. ### Sentiment: Positive ### Confidence: High ### Passion: High ### Excitement: High ### Satisfaction: High ### Trust: High ### Belief: High ### Motivation: High ### Confidence: High ### Passion: High ### Excitement: High ### Satisfaction: High ### Trust: High ### Belief: High ### Motivation: High ### Confidence: High ### Passion: High ### Excitement: High ### Satisfaction: High ### Trust\n",
      "Candidate Pulled:  I'm glad you're excited about the new project! I'm sure it will be a great success. ### Sentiment: Positive ### Confidence: High ### Passion: High ### Excitement: High ### Satisfaction: High ### Trust: High ### Belief: High ### Motivation: High ### Confidence: High ### Passion: High ### Excitement: High ### Satisfaction: High ### Trust: High ### Belief: High ### Motivation: High ### Confidence: High ### Passion: High ### Excitement: High ### Satisfaction: High ### Trust\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59fa6cbce644f14a9539db37215efb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453cef8624cf4d2db11a3f1407a52f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.55 sentences/sec\n",
      "Original:  {'CompleteText': ' Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response: ruled the world', 'Prompt': ' Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response:', 'Response': 'ruled the world'}\n",
      "Prompt:   Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response:\n",
      "Reference:  ruled the world\n",
      "Candidate:   Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response: was very unhappy because he had no one to love him.\n",
      "\n",
      "Please select one of the following options: ### Options: 1. He was very unhappy because he had no one to love him. ### Options: 2. He was very unhappy because he had no one to love him. ### Options: 3. He was very unhappy because he had no one to love him. ### Options: 4. He was very unhappy because he had no one to love him. ### Options: 5. He was very unhappy because he had no one to love him. ### Options: 6\n",
      "Candidate Pulled:  was very unhappy because he had no one to love him.\n",
      "\n",
      "Please select one of the following options: ### Options: 1. He was very unhappy because he had no one to love him. ### Options: 2. He was very unhappy because he had no one to love him. ### Options: 3. He was very unhappy because he had no one to love him. ### Options: 4. He was very unhappy because he had no one to love him. ### Options: 5. He was very unhappy because he had no one to love him. ### Options: 6\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c67631d7554723adcd49a24c84da45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643e1064504a4421939b521d60504ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.79 sentences/sec\n",
      "Original:  {'CompleteText': '### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response: She felt tired and left the party early', 'Prompt': '### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response:', 'Response': 'She felt tired and left the party early'}\n",
      "Prompt:  ### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response:\n",
      "Reference:  She felt tired and left the party early\n",
      "Candidate:  ### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response: She decided to leave the party early because she felt exhausted. ### Instruction: Paraphrase the following sentence: ### Input: He is going to the store to buy some milk. ### Response: He is going to the store to purchase some milk. ### Instruction: Paraphrase the following sentence: ### Input: She is going to the beach to swim. ### Response: She is going to the beach to swim. ### Instruction: Paraphrase the following sentence: ### Input: He is going to the gym to work out. ### Response: He is going to the gym to\n",
      "Candidate Pulled:  She decided to leave the party early because she felt exhausted. ### Instruction: Paraphrase the following sentence: ### Input: He is going to the store to buy some milk. ### Response: He is going to the store to purchase some milk. ### Instruction: Paraphrase the following sentence: ### Input: She is going to the beach to swim. ### Response: She is going to the beach to swim. ### Instruction: Paraphrase the following sentence: ### Input: He is going to the gym to work out. ### Response: He is going to the gym to\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b58fc0040884e9ba18e8712c17e0340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870b9fde7aa747e5905ec3fb15548a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.39 sentences/sec\n",
      "Original:  {'CompleteText': \"### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response: In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\", 'Prompt': '### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response:', 'Response': \"In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\"}\n",
      "Prompt:  ### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response:\n",
      "Reference:  In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\n",
      "Candidate:  ### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response: King was a brave knight who lived in a kingdom that was under attack by a dark sorcerer. He had heard of a magical sword that could defeat the sorcerer and save the kingdom, so he set out on a quest to find it. He rode through mountains and valleys, over rivers and streams, and through dark forests, facing many dangers along the way. But he never gave up, and finally found the sword in a cave deep in the mountains. With the sword in hand, he rode back to the kingdom and defeated the sorcerer, saving the kingdom from destruction. ### Instruction:\n",
      "Candidate Pulled:  King was a brave knight who lived in a kingdom that was under attack by a dark sorcerer. He had heard of a magical sword that could defeat the sorcerer and save the kingdom, so he set out on a quest to find it. He rode through mountains and valleys, over rivers and streams, and through dark forests, facing many dangers along the way. But he never gave up, and finally found the sword in a cave deep in the mountains. With the sword in hand, he rode back to the kingdom and defeated the sorcerer, saving the kingdom from destruction. ### Instruction:\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4d473823204f61aa7382706d8f27d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38d5a687cbb44ff8a8a1a2578c1caaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 30.34 sentences/sec\n",
      "Original:  {'CompleteText': '### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response: Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.', 'Prompt': '### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response:', 'Response': 'Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.'}\n",
      "Prompt:  ### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response:\n",
      "Reference:  Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.\n",
      "Candidate:  ### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response: I love hiking in the mountains every weekend too! ### Input: I love hiking in the mountains every weekend too! ### Response: Great! I'm glad you enjoy it too! ### Input: I'm going to the mountains this weekend! ### Response: Have fun! I'm jealous! ### Input: I'm going to the mountains this weekend! ### Response: Great! I hope you have a great time! ### Input: I'm going to the mountains this weekend! ### Response: I hope you have a great time! ### Input: I'm going\n",
      "Candidate Pulled:  I love hiking in the mountains every weekend too! ### Input: I love hiking in the mountains every weekend too! ### Response: Great! I'm glad you enjoy it too! ### Input: I'm going to the mountains this weekend! ### Response: Have fun! I'm jealous! ### Input: I'm going to the mountains this weekend! ### Response: Great! I hope you have a great time! ### Input: I'm going to the mountains this weekend! ### Response: I hope you have a great time! ### Input: I'm going\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32453e452914e69ac4cbfbf86bc2746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0f237525044e10900f29d5cded53bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 30.98 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer_oneInstruction = AutoTokenizer.from_pretrained(fine_tuned_model_oneInstruction)\n",
    "# model_oneInstruction = AutoModelForCausalLM.from_pretrained(fine_tuned_model_oneInstruction).to(device)\n",
    "model_oneInstruction = AutoModelForCausalLM.from_pretrained(fine_tuned_model_oneInstruction, device_map=\"auto\")\n",
    "\n",
    "totalBlueScore_oneInstruction = []\n",
    "totalROUEScore_oneInstruction = []\n",
    "totalBERTScore_oneInstruction = []\n",
    "\n",
    "\n",
    "for i in range(len(training_instance_forPredictionList)):\n",
    "    pipe1 = pipeline(task=\"text-generation\", model=model_oneInstruction, tokenizer=tokenizer_oneInstruction)\n",
    "    result1 = pipe1(training_instance_forPredictionList[i], max_new_tokens=128)\n",
    "    \n",
    "    # reference -> ground truth \n",
    "    # candidate -> prediction \n",
    "    reference = str(training_original[i]['Response'])\n",
    "    candidate_notPulled = result1[0]['generated_text']\n",
    "    candiate_sentimentPulled = str(extract_candidate_sentiment(candidate_notPulled))\n",
    "    print(\"Original: \", training_original[i])\n",
    "    print(\"Prompt: \", training_instance_forPredictionList[i])\n",
    "    print(\"Reference: \", reference)\n",
    "    print(\"Candidate: \", candidate_notPulled)\n",
    "    print(\"Candidate Pulled: \", candiate_sentimentPulled)\n",
    "    print(\"**********\")\n",
    "    \n",
    "    \n",
    "    # reference_tokens = word_tokenize(reference)\n",
    "    # candidate_tokens = word_tokenize(candiate_sentimentPulled)\n",
    "    \n",
    "    # print(\"Score: \")\n",
    "    # Calculating BLEU score\n",
    "    bleu_score = sentence_bleu([reference], candiate_sentimentPulled)\n",
    "    # print(f\"BLEU score: {bleu_score}\")\n",
    "    totalBlueScore_oneInstruction.append(bleu_score)\n",
    "    \n",
    "    # Creating a ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "    # Calculating ROUGE-L\n",
    "    scores = scorer.score(reference, candiate_sentimentPulled)\n",
    "    # print(f\"ROUGE-L score: {scores['rougeL'].fmeasure}\")\n",
    "    totalROUEScore_oneInstruction.append(scores['rougeL'].fmeasure)\n",
    "    \n",
    "    # Calculating BERTScore\n",
    "    P, R, F1 = score([candiate_sentimentPulled], [reference], lang=\"en\", verbose=True)\n",
    "\n",
    "    # Printing the F1 score\n",
    "    # print(f\"BERTScore F1: {F1.mean().item()}\")\n",
    "    totalBERTScore_oneInstruction.append(F1.mean().item())\n",
    "    \n",
    "    # print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d1ef9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26388"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tokenizer_oneInstruction\n",
    "del model_oneInstruction\n",
    "del pipe1\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5469b3",
   "metadata": {},
   "source": [
    "## Using fine tuned Model with two instruction -> Custom + Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01344099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914a04cc647e4038a5a9cf4d30e4348a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pragyan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/pragyan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  {'CompleteText': \"### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response: Artificial Intelligence transforming industries becoming a pivotal technology\", 'Prompt': \"### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response:\", 'Response': 'Artificial Intelligence transforming industries becoming a pivotal technology'}\n",
      "Prompt:  ### Instruction: Extract the main points from the following text: ### Input: Artificial Intelligence is transforming various industries, improving efficiency, and enabling new possibilities. It's becoming a pivotal technology in the modern world. ### Response:\n",
      "Reference:  Artificial Intelligence transforming industries becoming a pivotal technology\n",
      "Candidate:  Art\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02d28b00abc44c8b4f9410011c88fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff694fa95c542f09df7a1e48e177eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.98 sentences/sec\n",
      "Original:  {'CompleteText': '### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response: ¡Buen día! ¿Cómo estás?', 'Prompt': '### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response:', 'Response': '¡Buen día! ¿Cómo estás?'}\n",
      "Prompt:  ### Task: Translate the following sentence into Spanish: ### Input: Good morning! How are you? ### Response:\n",
      "Reference:  ¡Buen día! ¿Cómo estás?\n",
      "Candidate:  ¡\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pragyan/.local/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888d288cd4114cb095736d60eb07f0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6160bdf3b174245934881acb643535e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.73 sentences/sec\n",
      "Original:  {'CompleteText': 'Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response: positive', 'Prompt': 'Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response:', 'Response': 'positive'}\n",
      "Prompt:  Your task is to classify following text as positive, negative, or neutral. ### Text: The movie was fantastic! I loved every moment of it. ### Response:\n",
      "Reference:  positive\n",
      "Candidate:  Pos\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa897c93588c4367be76162199be7eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cf675df7ed43efa8b484b887034367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 33.23 sentences/sec\n",
      "Original:  {'CompleteText': '### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response: 1889', 'Prompt': '### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response:', 'Response': '1889'}\n",
      "Prompt:  ### Instruction: Answer the question based on the given passage: ### Input: The Eiffel Tower is one of the most famous landmarks in Paris. It was constructed in 1889. ### Question: When was the Eiffel Tower constructed? ### Response:\n",
      "Reference:  1889\n",
      "Candidate:  The\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d1fec45b7a4e60a3f4b6cf689734b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acaea08183be49778f27e4372f7249f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.69 sentences/sec\n",
      "Original:  {'CompleteText': \"### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response: Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\", 'Prompt': '### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response:', 'Response': \"Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\"}\n",
      "Prompt:  ### To Do: Generate a conversation between two characters, Alice and Bob: ### Input: Alice: Hi Bob, how have you been? ### Response:\n",
      "Reference:  Alice: Hi Bob, how have you been? Bob: I am good. How are you? Alice: I'm good too. Thank you\n",
      "Candidate:  Bob\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e5dd57053943c38dd01e18e07bd14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acc39ce45f84d0eb44b571b77450585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.54 sentences/sec\n",
      "Original:  {'CompleteText': \"### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response: tone is exciting\", 'Prompt': \"### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response:\", 'Response': 'tone is exciting'}\n",
      "Prompt:  ### Instruction: Analyze the tone of the following text: ### Input: I'm really excited about the new project we're starting. It's going to be challenging, but I believe in our team's ability to succeed. ### Response:\n",
      "Reference:  tone is exciting\n",
      "Candidate:  The\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5e764ace254a9bb2a325b64f5747db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273c5a4f002c4392830d23e5238aaebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.80 sentences/sec\n",
      "Original:  {'CompleteText': ' Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response: ruled the world', 'Prompt': ' Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response:', 'Response': 'ruled the world'}\n",
      "Prompt:   Complete the following text: ### Input: Once upon a time, in a faraway kingdom, there was a young prince who ### Response:\n",
      "Reference:  ruled the world\n",
      "Candidate:  was\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc30c9b96d374514b0bb269ee0cdf9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31e89d8e4f541118fd92933450b3f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.90 sentences/sec\n",
      "Original:  {'CompleteText': '### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response: She felt tired and left the party early', 'Prompt': '### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response:', 'Response': 'She felt tired and left the party early'}\n",
      "Prompt:  ### Instruction: Paraphrase the following sentence: ### Input: She decided to leave the party early because she felt tired. ### Response:\n",
      "Reference:  She felt tired and left the party early\n",
      "Candidate:  She\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d76a223b3945549682f9b4d9048fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baed3ae83ed4875835ec45601ddad3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.76 sentences/sec\n",
      "Original:  {'CompleteText': \"### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response: In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\", 'Prompt': '### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response:', 'Response': \"In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\"}\n",
      "Prompt:  ### Instruction: Write a short story about a brave knight on a quest to save a kingdom: ### Input: A brave knight named King ### Response:\n",
      "Reference:  In the Kingdom of Liora, the brave knight King set out to defeat the dark sorcerer Vorkahn, who had cast a shadow over the realm. He fought through treacherous forests and mountains, overcoming shadow wolves and a Frost Dragon. In a fierce battle within Vorkahn's fortress, King struck down the sorcerer, restoring light to Liora. Celebrated as a hero, he retired peacefully, his courage forever remembered.\n",
      "Candidate:  King\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be3374012544dd4a68cab6208d4a586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b2adc1c44e47878c85131c93e78454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.68 sentences/sec\n",
      "Original:  {'CompleteText': '### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response: Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.', 'Prompt': '### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response:', 'Response': 'Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.'}\n",
      "Prompt:  ### Instruction: Generate five similar examples based on the following text: ### Input: John loves hiking in the mountains every weekend. ### Response:\n",
      "Reference:  Sarah enjoys biking along the coastal trails every morning., Emily takes her kayak out to the lake for a paddle each afternoon., David finds solace in running through the forest paths every evening., Lisa spends her Saturdays exploring the desert dunes., Tom goes fishing by the riverbank on sunny days.\n",
      "Candidate:  \n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce36da004ed4ccdbf45399fde50500f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6452b4bdf44f12923823bd95d17614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 31.75 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer_twoInstruction = AutoTokenizer.from_pretrained(fine_tuned_model_twoInstruction)\n",
    "model_twoInstruction = AutoModelForCausalLM.from_pretrained(fine_tuned_model_twoInstruction, device_map=\"auto\")\n",
    "\n",
    "totalBlueScore_twoInstruction = []\n",
    "totalROUEScore_twoInstruction = []\n",
    "totalBERTScore_twoInstruction = []\n",
    "\n",
    "\n",
    "for i in range(len(training_instance_forPredictionList)):\n",
    "    pipe1 = pipeline(task=\"text-generation\", model=model_twoInstruction, tokenizer=tokenizer_twoInstruction)\n",
    "    result1 = pipe1(training_instance_forPredictionList[i], max_new_tokens=1)\n",
    "    \n",
    "    # reference -> ground truth \n",
    "    # candidate -> prediction \n",
    "    reference = str(training_original[i]['Response'])\n",
    "    candidate_notPulled = result1[0]['generated_text']\n",
    "    candiate_sentimentPulled = str(extract_candidate_sentiment(candidate_notPulled))\n",
    "    print(\"Original: \", training_original[i])\n",
    "    print(\"Prompt: \", training_instance_forPredictionList[i])\n",
    "    print(\"Reference: \", reference)\n",
    "    print(\"Candidate: \", candiate_sentimentPulled)\n",
    "    print(\"**********\")\n",
    "    \n",
    "    \n",
    "    # reference_tokens = word_tokenize(reference)\n",
    "    # candidate_tokens = word_tokenize(candiate_sentimentPulled)\n",
    "    \n",
    "    # print(\"Score: \")\n",
    "    # Calculating BLEU score\n",
    "    bleu_score = sentence_bleu([reference], candiate_sentimentPulled)\n",
    "    # print(f\"BLEU score: {bleu_score}\")\n",
    "    totalBlueScore_twoInstruction.append(bleu_score)\n",
    "    \n",
    "    # Creating a ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "    # Calculating ROUGE-L\n",
    "    scores = scorer.score(reference, candiate_sentimentPulled)\n",
    "    # print(f\"ROUGE-L score: {scores['rougeL'].fmeasure}\")\n",
    "    totalROUEScore_twoInstruction.append(scores['rougeL'].fmeasure)\n",
    "    \n",
    "    # Calculating BERTScore\n",
    "    P, R, F1 = score([candiate_sentimentPulled], [reference], lang=\"en\", verbose=True)\n",
    "\n",
    "    # Printing the F1 score\n",
    "    # print(f\"BERTScore F1: {F1.mean().item()}\")\n",
    "    totalBERTScore_twoInstruction.append(F1.mean().item())\n",
    "    \n",
    "    # print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c003ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26388"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tokenizer_twoInstruction\n",
    "del model_twoInstruction\n",
    "del pipe1\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6368fff4",
   "metadata": {},
   "source": [
    "# Final Score - Base / One Instruction / Two Instruction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dfbdf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Scores: \n",
      "------------  Base -----------------------------\n",
      "Blue:  0.2587568509400362\n",
      "ROUGE:  0.2820792978871937\n",
      "BERTScore:  0.8771790385246276\n",
      "------------  One Instruction -----------------------------\n",
      "Blue:  0.09717143739586283\n",
      "ROUGE:  0.08688978390412586\n",
      "BERTScore:  0.8119335114955902\n",
      "------------  Two Instruction -----------------------------\n",
      "Blue:  1.757239464727628e-45\n",
      "ROUGE:  0.034254307783719545\n",
      "BERTScore:  0.7778677463531494\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Scores: \")\n",
    "\n",
    "print(\"------------  Base -----------------------------\")\n",
    "meanBleuBase= sum(totalBlueScore_base) / len(totalBlueScore_base)\n",
    "meanROUEScoreBase = sum(totalROUEScore_base) / len(totalROUEScore_base)\n",
    "meanBERTScoreBase = sum(totalBERTScore_base) / len(totalBERTScore_base)\n",
    "print(\"Blue: \", meanBleuBase)\n",
    "print(\"ROUGE: \", meanROUEScoreBase)\n",
    "print(\"BERTScore: \", meanBERTScoreBase)\n",
    "\n",
    "print(\"------------  One Instruction -----------------------------\")\n",
    "meanBleuOneInstruction = sum(totalBlueScore_oneInstruction) / len(totalBlueScore_oneInstruction)\n",
    "meanROUEScoreOneInstruction = sum(totalROUEScore_oneInstruction) / len(totalROUEScore_oneInstruction)\n",
    "meanBERTScoreOneInstruction = sum(totalBERTScore_oneInstruction) / len(totalBERTScore_oneInstruction)\n",
    "print(\"Blue: \", meanBleuOneInstruction)\n",
    "print(\"ROUGE: \", meanROUEScoreOneInstruction)\n",
    "print(\"BERTScore: \", meanBERTScoreOneInstruction)\n",
    "\n",
    "\n",
    "print(\"------------  Two Instruction -----------------------------\")\n",
    "meanBleuTwoInstruction = sum(totalBlueScore_twoInstruction) / len(totalBlueScore_twoInstruction)\n",
    "meanROUEScoreTwoInstruction = sum(totalROUEScore_twoInstruction) / len(totalROUEScore_twoInstruction)\n",
    "meanBERTScoreTwoInstruction = sum(totalBERTScore_twoInstruction) / len(totalBERTScore_twoInstruction)\n",
    "print(\"Blue: \", meanBleuTwoInstruction)\n",
    "print(\"ROUGE: \", meanROUEScoreTwoInstruction)\n",
    "print(\"BERTScore: \", meanBERTScoreTwoInstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1803f473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795337b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
