{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23549808",
   "metadata": {},
   "source": [
    "# Task - Fine tuning Llama2 7B instruct model on twitter sentiment classification dataset and alpaca dataset - Two instructions mixed - alpaca and custom - custom only used for the twitter dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c662a9e",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8546bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47b636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the model \n",
    "base_model = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "fine_tuned_model = \"llama2-finetunedSentimentClassificationTwoInstruction\"\n",
    "output_dir_forArgs = \"/home/pragyan/Desktop/Notebooks/Assignment3/FineTunedModels-Assignment3/TunedOnSentimentAndAlpaca/FromArgs\"\n",
    "output_dir_forSave = \"/home/pragyan/Desktop/Notebooks/Assignment3/FineTunedModels-Assignment3/TunedOnSentimentAndAlpaca/FromSave\"\n",
    "\n",
    "\n",
    "# loading the dataset\n",
    "dataset_name_twitter = \"carblacac/twitter-sentiment-analysis\"\n",
    "dataset_name_alpaca = \"tatsu-lab/alpaca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aca36a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pragyan/.local/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for carblacac/twitter-sentiment-analysis contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/carblacac/twitter-sentiment-analysis\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_dataset_twitter = load_dataset(dataset_name_twitter, split=\"train[0:4000]\")\n",
    "testing_dataset_twitter = load_dataset(dataset_name_twitter, split=\"test[-50:]\")\n",
    "\n",
    "training_dataset_alpaca = load_dataset(dataset_name_alpaca, split=\"train[0:4000]\")\n",
    "testing_dataset_alpaca = load_dataset(dataset_name_alpaca, split=\"train[-50:]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "105e8ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "50\n",
      "4000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(training_dataset_twitter))\n",
    "print(len(testing_dataset_twitter))\n",
    "\n",
    "print(len(training_dataset_alpaca))\n",
    "print(len(testing_dataset_alpaca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f768f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '@fa6ami86 so happy that salman won.  btw the 14sec clip is truely a teaser', 'feeling': 0}\n",
      "{'text': '@WULFFBOY going to see The Roots in SF', 'feeling': 1}\n",
      "{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}\n",
      "{'instruction': 'Create a Scratch program that generates a random number between 0 and 100.', 'input': '', 'output': \"The following Scratch program can be used to generate a random number between 0 and 100:\\n\\n1. Start by declaring a variable called 'randomNumber', and set it to 0.\\n2. Create a 'When Green Flag' clicked block and put the following code: set the randomNumber to a random integer between 0 to 100.\\n3. End the program with a 'Say' block to display the randomNumber.\", 'text': \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a Scratch program that generates a random number between 0 and 100.\\n\\n### Response:\\nThe following Scratch program can be used to generate a random number between 0 and 100:\\n\\n1. Start by declaring a variable called 'randomNumber', and set it to 0.\\n2. Create a 'When Green Flag' clicked block and put the following code: set the randomNumber to a random integer between 0 to 100.\\n3. End the program with a 'Say' block to display the randomNumber.\"}\n"
     ]
    }
   ],
   "source": [
    "print(training_dataset_twitter[0])\n",
    "print(testing_dataset_twitter[0])\n",
    "\n",
    "print(training_dataset_alpaca[0])\n",
    "print(testing_dataset_alpaca[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ba010b",
   "metadata": {},
   "source": [
    "# Creating the instruction dataset for the fine tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a1bbbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructionPrompt = \"Your task is to classify the the text into one of two feelings. Each feeling has two possible values: 0 indicates the text has a negative sentiment, while 1 indicates a positive feeling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4d74f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all the instruct here \n",
    "training_original = []\n",
    "training_instances = []\n",
    "\n",
    "# loop to create the instruction training data for fine tuning \n",
    "for i in training_dataset_twitter:\n",
    "    training_input = instructionPrompt + \" ### Text: \" + i['text'] + \" ### Sentiment: \" + str(i['feeling'])\n",
    "    training_instances.append(training_input)\n",
    "    training_original.append(i)\n",
    "\n",
    "for j in training_dataset_alpaca:\n",
    "    training_instances.append(j['text'])\n",
    "    training_original.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb461512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "Your task is to classify the the text into one of two feelings. Each feeling has two possible values: 0 indicates the text has a negative sentiment, while 1 indicates a positive feeling. ### Text: About to go to bed. Sleeping really late tomorrow!  I am so glad the Tigers won tonight!! ### Sentiment: 1\n"
     ]
    }
   ],
   "source": [
    "print(len(training_instances))\n",
    "print(training_instances[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef4ca6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['originalData'] = training_original\n",
    "df['instructionInputForFineTuning'] = training_instances\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "makeDataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7099480f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['originalData', 'instructionInputForFineTuning'],\n",
       "    num_rows: 8000\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bfead0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalData</th>\n",
       "      <th>instructionInputForFineTuning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'text': 'is playing the Aion beta  !!! Man I'...</td>\n",
       "      <td>Your task is to classify the the text into one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'text': 'just did a search for #wolframalpha ...</td>\n",
       "      <td>Your task is to classify the the text into one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'text': 'Cool! Nice result  Also, can I just ...</td>\n",
       "      <td>Your task is to classify the the text into one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'text': '@PandaMayhem i think. did you have 1...</td>\n",
       "      <td>Your task is to classify the the text into one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'instruction': 'Write a blog post about how A...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>{'instruction': 'Give five examples of an extr...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>{'instruction': 'Make a list of books and auth...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>{'text': '@MiniBlueDragon Has come on a long w...</td>\n",
       "      <td>Your task is to classify the the text into one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>{'instruction': 'Write a review of a restauran...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>{'instruction': 'Generate five adjectives to d...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           originalData  \\\n",
       "0     {'text': 'is playing the Aion beta  !!! Man I'...   \n",
       "1     {'text': 'just did a search for #wolframalpha ...   \n",
       "2     {'text': 'Cool! Nice result  Also, can I just ...   \n",
       "3     {'text': '@PandaMayhem i think. did you have 1...   \n",
       "4     {'instruction': 'Write a blog post about how A...   \n",
       "...                                                 ...   \n",
       "7995  {'instruction': 'Give five examples of an extr...   \n",
       "7996  {'instruction': 'Make a list of books and auth...   \n",
       "7997  {'text': '@MiniBlueDragon Has come on a long w...   \n",
       "7998  {'instruction': 'Write a review of a restauran...   \n",
       "7999  {'instruction': 'Generate five adjectives to d...   \n",
       "\n",
       "                          instructionInputForFineTuning  \n",
       "0     Your task is to classify the the text into one...  \n",
       "1     Your task is to classify the the text into one...  \n",
       "2     Your task is to classify the the text into one...  \n",
       "3     Your task is to classify the the text into one...  \n",
       "4     Below is an instruction that describes a task....  \n",
       "...                                                 ...  \n",
       "7995  Below is an instruction that describes a task....  \n",
       "7996  Below is an instruction that describes a task....  \n",
       "7997  Your task is to classify the the text into one...  \n",
       "7998  Below is an instruction that describes a task,...  \n",
       "7999  Below is an instruction that describes a task....  \n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e147eb",
   "metadata": {},
   "source": [
    "# Loading the model and setting up the quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eba2eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up bitsandbites configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit= True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd0d179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f555d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c171d29a7e8b4955a8b2b414c43bd3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the model \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f88af",
   "metadata": {},
   "source": [
    "# Setting up the LORA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ae5952c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4405092352"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        'q_proj',\n",
    "        'k_proj',\n",
    "        'v_proj',\n",
    "        'dense',\n",
    "        'fc1',\n",
    "        'fc2',\n",
    "    ]\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.get_memory_footprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca76cd3",
   "metadata": {},
   "source": [
    "# Set the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "153d2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir= output_dir_forArgs,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=5000,\n",
    "    logging_steps=1000,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    disable_tqdm=False,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7f45b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2ca88b629e40e6aa947943773f229e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pragyan/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:317: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "/home/pragyan/.local/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=makeDataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length= 2048,\n",
    "    dataset_text_field=\"instructionInputForFineTuning\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9e9dd",
   "metadata": {},
   "source": [
    "# Training Begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f849461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pragyan/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 32:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.039200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.947800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=0.9934906005859375, metrics={'train_runtime': 1937.8869, 'train_samples_per_second': 4.128, 'train_steps_per_second': 1.032, 'total_flos': 3.221637556292813e+16, 'train_loss': 0.9934906005859375, 'epoch': 1.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77be144",
   "metadata": {},
   "source": [
    "# Saving the fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59381754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llama2-finetunedSentimentClassificationTwoInstruction/tokenizer_config.json',\n",
       " 'llama2-finetunedSentimentClassificationTwoInstruction/special_tokens_map.json',\n",
       " 'llama2-finetunedSentimentClassificationTwoInstruction/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(output_dir_forSave)\n",
    "trainer.save_model(fine_tuned_model)\n",
    "trainer.tokenizer.save_pretrained(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a78091",
   "metadata": {},
   "source": [
    "# Testing the new fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3345fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPrompt = \"Your task is to classify the the text into one of two feelings. Each feeling has two possible values: 0 indicates the text has a negative sentiment, while 1 indicates a positive feeling. ### Text: I hate the V plotarc on True Blood  that poor chubby vampire guy getting staked was so sad. ### Sentiment: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "747e826d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c4dada0ed749b482b3efe634fe2378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to classify the the text into one of two feelings. Each feeling has two possible values: 0 indicates the text has a negative sentiment, while 1 indicates a positive feeling. ### Text: I hate the V plotarc on True Blood  that poor chubby vampire guy getting staked was so sad. ### Sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(task=\"text-generation\",\n",
    "                model=base_model,\n",
    "                tokenizer=tokenizer,\n",
    "                max_new_tokens=1)\n",
    "result = pipe(f\"{testPrompt}\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c18a5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac602f521ed049539c7f877ccde24ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to classify the the text into one of two feelings. Each feeling has two possible values: 0 indicates the text has a negative sentiment, while 1 indicates a positive feeling. ### Text: I hate the V plotarc on True Blood  that poor chubby vampire guy getting staked was so sad. ### Sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "pipe1 = pipeline(task=\"text-generation\",\n",
    "                model=fine_tuned_model,\n",
    "                tokenizer=fine_tuned_model,\n",
    "                max_new_tokens=1)\n",
    "result1 = pipe1(f\"{testPrompt}\")\n",
    "print(result1[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c556244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595765a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
